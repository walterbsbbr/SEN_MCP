import os
import sys
import json
import asyncio
from datetime import datetime
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from groq import Groq
from dotenv import load_dotenv

# Importa as ferramentas diretas (sem MCP)
from senado_camara_tools import AVAILABLE_TOOLS, TOOLS_SCHEMA

# --- Configura√ß√£o de Ambiente ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ENV_FILE = os.path.join(BASE_DIR, ".env")

# Carrega vari√°veis de ambiente
load_dotenv(ENV_FILE)

GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# Inicializa cliente Groq
groq_client = Groq(api_key=GROQ_API_KEY) if GROQ_API_KEY else None

# --- Helpers ---

def get_system_date_context():
    """Retorna a string de contexto com a data atual."""
    now = datetime.now()
    return f"Hoje √© dia {now.strftime('%d/%m/%Y')} (Dia da semana: {now.strftime('%A')}). O hor√°rio atual √© {now.strftime('%H:%M')}."


# --- App Setup ---
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)


class ChatRequest(BaseModel):
    message: str
    history: list = []
    model: str = "gemini"


@app.get("/api/health")
async def health_check():
    return {
        "status": "ok",
        "tools_available": len(AVAILABLE_TOOLS),
        "tools_list": list(AVAILABLE_TOOLS.keys())
    }


@app.post("/api/chat")
async def chat_endpoint(request: ChatRequest):
    if request.model == "groq":
        return await chat_with_groq(request)
    else:
        return await chat_with_gemini(request)


# --- Groq Logic ---

async def chat_with_groq(request: ChatRequest):
    if not groq_client:
        raise HTTPException(500, "Groq API key missing")
    
    try:
        # System prompt FOR√áANDO uso de ferramentas
        system_msg = {
            "role": "system",
            "content": f"""Voc√™ √© um assistente especializado em dados do Senado Federal e C√¢mara dos Deputados do Brasil. {get_system_date_context()}

REGRA CR√çTICA: Voc√™ DEVE SEMPRE usar as ferramentas dispon√≠veis para responder perguntas sobre dados legislativos.

NUNCA invente informa√ß√µes. Se o usu√°rio perguntar sobre senadores, deputados, proposi√ß√µes, vota√ß√µes, reuni√µes, agendas - SEMPRE chame a ferramenta apropriada.

Voc√™ tem 31 ferramentas dispon√≠veis. USE-AS para buscar dados reais."""
        }
        messages = [system_msg] + request.history + [{"role": "user", "content": request.message}]

        # Converte ferramentas para formato Groq
        tools_groq = []
        for tool in TOOLS_SCHEMA:
            tools_groq.append({
                "type": "function",
                "function": {
                    "name": tool["name"],
                    "description": tool["description"],
                    "parameters": {
                        "type": "object",
                        "properties": {
                            k: {"type": v.get("type", "string").lower(), "description": v.get("description", "")}
                            for k, v in tool["parameters"].get("properties", {}).items()
                        },
                        "required": tool["parameters"].get("required", [])
                    }
                }
            })

        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=messages,
            tools=tools_groq if tools_groq else None,
            tool_choice="auto" if tools_groq else None
        )

        # Se h√° chamadas de ferramentas
        if response.choices[0].message.tool_calls:
            for tool_call in response.choices[0].message.tool_calls:
                fn_name = tool_call.function.name
                fn_args = json.loads(tool_call.function.arguments)

                print(f"ü§ñ Groq chamou: {fn_name} com args: {fn_args}")

                # Executa a ferramenta diretamente
                tool_output = "Erro: ferramenta n√£o encontrada"
                if fn_name in AVAILABLE_TOOLS:
                    try:
                        result = AVAILABLE_TOOLS[fn_name](**fn_args)
                        tool_output = json.dumps(result, ensure_ascii=False)
                    except Exception as e:
                        tool_output = f"Erro ao executar {fn_name}: {str(e)}"
                        print(f"‚ùå Erro na ferramenta: {e}")

                # Adiciona resultado ao hist√≥rico
                messages.append(response.choices[0].message)
                messages.append({
                    "role": "tool",
                    "content": tool_output,
                    "tool_call_id": tool_call.id
                })

                # Faz nova chamada com o resultado
                final_res = groq_client.chat.completions.create(
                    model="llama-3.3-70b-versatile",
                    messages=messages
                )
                return {"reply": final_res.choices[0].message.content}

        return {"reply": response.choices[0].message.content}

    except Exception as e:
        print(f"‚ùå Erro Groq: {e}")
        raise HTTPException(500, str(e))


# --- Gemini Logic ---

async def chat_with_gemini(request: ChatRequest):
    try:
        import google.generativeai as genai
    except ImportError:
        raise HTTPException(500, "google-generativeai missing")

    if not GOOGLE_API_KEY:
        raise HTTPException(500, "Google API key missing")

    genai.configure(api_key=GOOGLE_API_KEY)

    # System instruction FOR√áANDO uso de ferramentas
    system_instruction = f"""Voc√™ √© um assistente especializado em dados do Senado Federal e C√¢mara dos Deputados do Brasil. {get_system_date_context()} 

REGRA CR√çTICA: Voc√™ DEVE SEMPRE usar as ferramentas dispon√≠veis para responder perguntas sobre:
- Senadores, deputados, comiss√µes
- Proposi√ß√µes, vota√ß√µes, reuni√µes
- Agendas, eventos, despesas
- Qualquer dado legislativo

NUNCA invente ou adivinhe informa√ß√µes. Se o usu√°rio perguntar algo sobre dados legislativos, SEMPRE chame a ferramenta apropriada primeiro.

Exemplos:
- "Quem s√£o os senadores de SP?" -> CHAME buscar_senadores(uf="SP")
- "Qual o ID da reuni√£o da CCJ de 17/12/2025?" -> CHAME buscar_agenda_comissao(data_inicio="20251217")
- "Busque proposi√ß√µes PEC de 2025" -> CHAME buscar_proposicoes_senado(sigla="PEC", ano="2025")

Voc√™ tem 31 ferramentas dispon√≠veis. USE-AS."""

    model = genai.GenerativeModel(
        'gemini-2.0-flash-exp',
        tools=TOOLS_SCHEMA if TOOLS_SCHEMA else None,
        system_instruction=system_instruction
    )

    chat = model.start_chat(history=request.history)

    try:
        response = chat.send_message(request.message)

        # Loop de execu√ß√£o de ferramentas
        max_iterations = 10
        iteration = 0

        while response.candidates and response.candidates[0].content.parts:
            iteration += 1
            if iteration > max_iterations:
                print("‚ö†Ô∏è Limite de itera√ß√µes atingido")
                break

            # Verifica se h√° chamada de ferramenta
            has_function_call = False
            for part in response.candidates[0].content.parts:
                if hasattr(part, 'function_call') and part.function_call:
                    has_function_call = True
                    fn_call = part.function_call
                    fn_name = fn_call.name
                    fn_args = dict(fn_call.args)

                    print(f"ü§ñ Gemini chamou: {fn_name} com args: {fn_args}")

                    # Executa a ferramenta diretamente
                    tool_output = ""
                    if fn_name in AVAILABLE_TOOLS:
                        try:
                            result = AVAILABLE_TOOLS[fn_name](**fn_args)
                            tool_output = json.dumps(result, ensure_ascii=False)
                            print(f"‚úÖ Resultado obtido com sucesso")
                        except Exception as e:
                            tool_output = f"Erro ao executar {fn_name}: {str(e)}"
                            print(f"‚ùå Erro na ferramenta: {e}")
                    else:
                        tool_output = f"Ferramenta {fn_name} n√£o encontrada."
                        print(f"‚ö†Ô∏è Ferramenta n√£o encontrada: {fn_name}")

                    # Envia resultado de volta ao Gemini
                    response = chat.send_message(
                        genai.protos.Content(parts=[
                            genai.protos.Part(
                                function_response=genai.protos.FunctionResponse(
                                    name=fn_name,
                                    response={'result': tool_output}
                                )
                            )
                        ])
                    )
                    break

            if not has_function_call:
                break

        return {"reply": response.text}

    except Exception as e:
        print(f"‚ùå Erro Gemini: {e}")
        return {"reply": f"Erro interno: {e}"}


# Para desenvolvimento local
if __name__ == "__main__":
    import uvicorn
    print("üöÄ Iniciando servidor na porta 8000...")
    print(f"üìä {len(AVAILABLE_TOOLS)} ferramentas carregadas (31 esperadas)")
    print(f"‚úÖ Ferramentas: {', '.join(list(AVAILABLE_TOOLS.keys())[:5])}...")
    uvicorn.run(app, host="0.0.0.0", port=8000)
